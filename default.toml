# log_file specifies the location to log API requests
log_file = "/var/log/chef-load/chef-load.log"

# The Authorization token for the Automate server.
# The following default value is sufficient unless you set your own token in your Automate server.
data_collector_token = "93a49a4f2482c64126f7b6015e6b0f30284287ee4054ff8807fb63d9cbd1c506"

# Ohai data will be loaded from this file and used for the nodes' automatic attributes.
# See the chef-load README for instructions for creating an ohai JSON file.
# ohai_json_file = "/hab/svc/chef-load/static/sample-data/example-ohai.json"

# Data from a converge status report will be loaded from this file and used
# for each node's converge status report that is sent to the Automate server.
# See the chef-load README for instructions for creating a converge status JSON file.
# converge_status_json_file = "/hab/svc/chef-load/static/sample-data/example-converge-status.json"

# Data from a compliance status report will be loaded from this file and used
# for each node's compliance status report that is sent to the Automate server.
# See the chef-load README for instructions for creating a compliance status JSON file.
# compliance_status_json_file = "/hab/svc/chef-load/static/sample-data/example-compliance-status.json"

# chef-load will evenly distribute the number of nodes across the desired interval (minutes)
# Examples:
#   30 nodes / 30 minute interval =  1 chef-client run per minute
# 1800 nodes / 30 minute interval = 60 chef-client runs per minute
num_nodes = 30
interval = 30

# During the same interval of time, it is also possible to load a number of Chef actions
num_actions = 30

# This prefix will go at the beginning of each node name.
# This enables running multiple instances of chef-load without affecting each others' nodes
# For example, a value of "chef-load" will result in nodes named "chef-load-1", "chef-load-2", ...
node_name_prefix = "chef-load"

# Chef environment used for each node
chef_environment = "_default"

# run_list is the run list used for each node. It should be a list of strings.
# For example: run_list = [ "role[role_name]", "recipe_name", "recipe[different_recipe_name@1.0.0]" ]
# The default value is an empty run_list.
run_list = [ ]

# sleep_duration is an optional setting that is available to provide a delay to simulate
# the amount of time a Chef Client takes actually converging all of the run list's resources.
# sleep_duration is measured in seconds
sleep_duration = 0

# download_cookbooks controls which chef-client run downloads cookbook files.
# Options are: "never", "first" (first chef-client run only), "always"
#
# Downloading cookbooks can significantly increase the number of API requests that chef-load
# makes depending on the run_list. If you aren't concerned with simulating the download of cookbook files
# then the recommendation is to use "never" or "first".
#
download_cookbooks = "never"

# api_get_requests is an optional list of API GET requests that are made during the chef-client run.
# This is used to simulate the API requests that the cookbooks would make.
# For example, it can make Chef Search or data bag item requests.
# The values can be either full URLs that include the chef_server_url portion or just the portion of
# the URL that comes after the chef_server_url.
# For example, to make a Chef Search API request that searches for all nodes you can use either of the
# following values:
#
# "https://chef.example.com/organizations/orgname/search/node?q=*%253A*&sort=X_CHEF_id_CHEF_X%20asc&start=0"
# or
# "search/node?q=*%253A*&sort=X_CHEF_id_CHEF_X%20asc&start=0"
#
api_get_requests = [ ]

# chef_version sets the value of the X-Chef-Version HTTP header in API requests sent to the Chef Server.
# This value represents the version of the Chef Client making the API requests. The default is "13.2.20"
chef_version = "13.2.20"

# Ever since Chef Client 12.x was released the default behavior has been for the Chef Client to create its
# own client key locally and then upload the public side to the Chef Server when it creates the client object.
# chef-load simulates this behavior. However, if you want chef-load to ask the Chef Server to create a client key
# when the client object is created then set chef_server_creates_client_key to true.
chef_server_creates_client_key = false

# Send data to the Chef server's Reporting service
enable_reporting = false

# Generate Random Data
random_data = true

# Generate Liveness Agent Data
liveness_agent = true

# The chef_server_url, client_name and client_key parameters must be set if you want
# to make API requests to a Chef Server.
#
# chef-load will also automatically attempt to connect to the Chef Server authenticated data collector proxy.
# If you enabled this feature on the Chef Server, Chef Client run data will automatically be forwarded to Automate.
# If you do not have Automate or the feature is disabled on the Chef Server, chef-load will detect this and
# disable data collection.
#
# Be sure to include the organization name
# For example: "https://chef.example.com/organizations/demo/"
#
# These options combined make the "chef_server_url" setting in the chef-load
# config file.
#
# If a binding is used (`--bind chef-server:chef-server-default`), that will be used
# instead of the values here.
#
# If host is not set, chef_server_url will not be set in the chef-load config file.
[chef_server]

protocol = "https"
# host = "localhost"
port = 443
organization = "demo"

# The client defined by client_name needs to be an admin user of the Chef Server org.
# client_name = "CLIENT_NAME"
# client_key_path = "/path/to/CLIENT_NAME.pem"
# client_key = ""

# The data collector url must be set if you want to make API requests directly to an Automate server.
# For example: "https://automate.example.org/data-collector/v0/"
#
# These options combined make the "data_collector_url" setting in the chef-load
# config file.
#
# If a binding is used (`--bind automate:automate-default`), that will be used
# instead of the values here.
#
# If host is not set, data_collector_url will not be set in the chef-load config file.
[data_collector]

protocol = "https"
# host = "localhost"
port = 443
path = "data-collector/v0"


# Matrix settings for Compliance Generation.  This is to ensure a diversity of nodes/scan/profiles
# for compliance data. This only applied when running in "this day back" or "generate" mode.
[matrix]
  #The samples listed in this section (matrix.samples), specify the profiles that each individual node will have included in their respective scans.
  [matrix.samples]
    [[matrix.samples.platforms]]
    name = "c5"
    target = "ssh://root@0.0.0.0:11032"
    profiles = [
      "mylinux-success-1.8.9"
    ]

    [[matrix.samples.platforms]]
    name = "c6"
    target = "ssh://root@0.0.0.0:11024"
    profiles = [
      "cis-centos6-level1-1.1.0-1.4",
      "ssh-baseline-2.2.0"
    ]

    [[matrix.samples.platforms]]
    name = "c7"
    target = "ssh://root@0.0.0.0:11025"
    profiles = [
      "mylinux-success-1.8.9"
    ]

    [[matrix.samples.platforms]]
    name = "d7"
    target = "ssh://root@0.0.0.0:11029"
    profiles = [
      "apache-baseline-2.0.2"
    ]

    [[matrix.samples.platforms]]
    name = "d8"
    target = "ssh://root@0.0.0.0:11028"
    profiles = [
      "mylinux-failure-minor-5.2.0"
    ]

    [[matrix.samples.platforms]]
    name = "d8-2"
    target = "ssh://root@0.0.0.0:11028"
    profiles = [
      "mylinux-failure-major-5.4.4"
    ]

    [[matrix.samples.platforms]]
    name = "f22"
    target = "ssh://root@0.0.0.0:11026"
    profiles = [
      "linux-baseline-2.2.0",
      "ssh-baseline-2.2.0",
      "apache-baseline-2.0.2",
      "mysql-baseline-2.1.0"
    ]

    [[matrix.samples.platforms]]
    name = "u12"
    target = "ssh://root@0.0.0.0:11022"
    profiles = [
      "cis-ubuntu12_04lts-level1-1.1.0-2"
    ]

    [[matrix.samples.platforms]]
    name = "u14"
    target = "ssh://root@0.0.0.0:11031"
    profiles = [
      "mylinux-success-1.8.9"
    ]

    [[matrix.samples.platforms]]
    name = "u18"
    target = "ssh://root@0.0.0.0:11033"
    profiles = [
      "linux-baseline-2.2.0",
      "ssh-baseline-2.2.0"
    ]

  [matrix.simulation]
  days = 2
  nodes = 10
  max_scans = 3
  total_max_scans = 1000000
  format = "full"

  [matrix.statistics]

    [[matrix.statistics.sets]]
    nodes = 10
    scan_per_day = 1

    [[matrix.statistics.sets]]
    nodes = 10
    scan_per_day = 24

    [[matrix.statistics.sets]]
    nodes = 100
    scan_per_day = 1

    [[matrix.statistics.sets]]
    nodes = 100
    scan_per_day = 24

    [[matrix.statistics.sets]]
    nodes = 1000
    scan_per_day = 1

    [[matrix.statistics.sets]]
    nodes = 1000
    scan_per_day = 24

    [[matrix.statistics.sets]]
    nodes = 10000
    scan_per_day = 1

    [[matrix.statistics.sets]]
    nodes = 10000
    scan_per_day = 24

    [[matrix.statistics.sets]]
    nodes = 10000
    scan_per_day = 96
